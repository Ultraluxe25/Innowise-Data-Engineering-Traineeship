<h1 align="center">Data Skew</h1>


## Description

Здесь вы познакомитесь с очень важной проблемой которая есть у всех распределенных систем, а именно перекос данных.


## Theory about Data Skew

В переводе на русский это перекос данных. До тех пор пока у вас все на одной машине вы не сталкнетесь с такой проблемой(вернее она может быть, вот только
на производительность она не повлияет так сильно). Суть проблемы сразу на примере: пусть у вас есть форма для заполнения где почта необязательный параметр. В таком
случае у вас большинство пользователей не будут его вводить. Таким образом, в ваших данных будет перекос по этому полю(для простоты 50% где ввели почту и 50% где не
ввели). Очевидно что видов почт много и поэтому 50% введенных почт будут плюс минус нормально распрделены, а вот отсутствие почт становится реальной проблемой.
Но в чём же проблема? Например вы хотите сгруппировать по полю почта, чтобы посмотреть собрать агрегированные данные. Под капотом спарк сделает shuffle, чтобы
данные с одним ключом были в одной партиции. И вот у вас будут плюс минус адекватные партиции с почтами, а там где их нет будет просто огромнейшая одна партиция.
Тут возможны два варианта: первый это спарк сможет поместить эту партицию в оперативку, а значит он будет работать пусть и очень очень медленно. В случае же если
партиция будет больше размера оперативки то ваш executor просто упадёт. Вот приблизительно так выглядит описание проблемы, которая встречается реально часто.

## Strategies to solve problem

- Ну самый просто это broadcast hash join(ну очевидно если вы джойните). С этим типом соединения вы уже знакомы, суть его в том чтобы сделать хэш-таблицу из наименьшего
датафрейма, перекинуть её на драйвер, драйвер соединит кусочки хэш-таблицы с разных работников и после отправит целую хэш-мапу на все работники. Тут важно понимать
что является для вашего кластера маленький датафрейм, ибо на драйвер лучше не скидывать много всего. Каким параметром регулируется вы знаете, но так же добавлю что
AQE сам может решить делать это или нет. Так же можно спровоцировать этот тип джойна с помощью хинта broadcast прямо в коде.

- Чуть посложнее это salting. Вот статья которая достаточно хорошо объясняет: https://towardsdatascience.com/skewed-data-in-spark-add-salt-to-compensate-16d44404088b.
На самом деле ещё можно делать через explode() функцию в спарке для join(в прошлой статье пример с group by), вот статья только про explode(не про сам salting): 
https://sparkbyexamples.com/spark/explode-spark-array-and-map-dataframe-column/. Как это применяется для соли при решении data skew во время Join думаю понятно.

- AQE. Работает в данном случае только при sort merge join. Сам AQE собирает статистику после певого этапа shuffle(shuffle write). В этот момент он может заметить 
что одна из партиций будет слишком большой и сделать следующее: взять и засолить её самостоятельно, тем самым получив из неё не 1 партицию а несколько поменьше. 
Да они все ещё будут на одном работнике(ибо партицию второго датасета не будешь же отправлять на разных работников), тем не менее сами партиции меньше, кол-во партиций
на работниках после shuffle равномерно распределяется а значит то что везде будут +- одинаковые по размерам партиции(так на том работнике было много партиций и одна
из них плюс ко всему мега большая, а так там будут те же данные большой партиции, только уже разбитые на маленькие партиции и само количество партиций будет на всех
работниках +-одинаковое). Ну и да, AQE не гений поэтому все настройки какие данные считать перекошенными и т.д. надо настраивать через конфиги.

![image](https://user-images.githubusercontent.com/113685144/194550587-439bbacb-50cc-4357-9623-10380032172c.png)

- Очевидно что существует ещё ряд способов, но они уже более индивидуальны под конкретную ситуацию и не так часто встречаются. В принципе соли и broadcast join
будет хватать выше крыше, ну а если ошиблись то AQE подчистит ваш косяк(по крайней мере постарается, пока ещё он не совершенен).

- Вот статься если кому интересно с тем что выше+ещё чуть-чуть: https://towardsdatascience.com/five-tips-to-fasten-your-skewed-joins-in-apache-spark-420f558b219e.

